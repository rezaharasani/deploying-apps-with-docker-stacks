# Backing up Swarm
Backing up a swarm will backup the *control plane objects* required to recover the swarm in the event of a catastrophic failure of corruption. Recovering a swarm from a backup is an extremely rare scenario. However, business critical environments should always be prepared for worst-case scenarios.  

Swarm configuration and state is stored in `/var/lib/docker/swarm` on every manager node. The configuration includes; Raft log keys, overlay networks, Secrets, Configs, Services, and more. A swarm backup is a copy of all the files in this directory.  

As the contents of this directory are replicated to all managers, you can, and should, perform backups from multiple managers. However, as you have to stop the Docker daemon on the node you are backing up, it’s a good idea to perform the bachup from non-leader managers. This is because stopping Docker on the leader will initiate a leader election. You should also perform the backup at a quiet time for the business, as stopping a manager can increase the risk of the swarm losing quorum if another manager fails during the backup.  

**Warning**: The following operation carries risks. You should also ensure you perform test backup
and restore operations regularly and test the outcomes.  

The following commands will create the following two objects so you can prove the restore operation:  
• An overlay network called *Unimatrix-01*  
• A Secret called “missing drones” containing the text *Seven of Nine*  

```
swarm-manager-02:~# docker network create -d overlay Unimatrix-01
w9l904ff73e7stly0gnztsud7

swarm-manager-02:~# printf "Seven of Nine" | docker secret create missing_drones -
i8oj3b2lid27t5202uycw37lg
```  


Let’s perform the swarm backup.  

1. Stop Docker on a non-leader swarm manager (like *swarm-manager-02* node).  
   If you have any containers or service tasks running on the node, this action may stop them.
   ```
   swarm-manager-02:~# service docker stop
   ```  
2. Backup the Swarm config.
   This example uses the Linux tar utility to perform the file copy that will be the backup. Feel free to use a different tool.
   ```
   swarm-manager-02:~# tar -czvf swarm.bkp /var/lib/docker/swarm/
   tar: Removing leading `/' from member names
   /var/lib/docker/swarm/
   /var/lib/docker/swarm/docker-state.json
   /var/lib/docker/swarm/state.json
   /var/lib/docker/swarm/worker/
   /var/lib/docker/swarm/worker/tasks.db
   /var/lib/docker/swarm/raft/
   /var/lib/docker/swarm/raft/snap-v3-encrypted/
   /var/lib/docker/swarm/raft/snap-v3-encrypted/0000000000000004-0000000000000054.snap
   /var/lib/docker/swarm/raft/wal-v3-encrypted/
   /var/lib/docker/swarm/raft/wal-v3-encrypted/0000000000000000-0000000000000000.wal
   /var/lib/docker/swarm/certificates/
   /var/lib/docker/swarm/certificates/swarm-node.key
   /var/lib/docker/swarm/certificates/swarm-node.crt
   /var/lib/docker/swarm/certificates/swarm-root-ca.crt
   ```  
3. Verify the backup file exists.  
   ```
   swarm-manager-02:~# ls -l
   -rw-r--r-- 1 root root 1700500 Apr 11 18:31 swarm.bkp
   ```  
4. Restart Docker.  
   ```
   swarm-manager-02:~# service docker restart
   
   swarm-manager-02:~# service docker status
   ● docker.service - Docker Application Container Engine
        Loaded: loaded (/lib/systemd/system/docker.service; enabled; preset: enabled)
        Active: active (running) since Thu 2024-04-11 18:32:27 +0330; 3min 7s ago
   TriggeredBy: ● docker.socket
          Docs: https://docs.docker.com
      Main PID: 25007 (dockerd)
         Tasks: 9
        Memory: 92.4M
           CPU: 2.538s
        CGroup: /system.slice/docker.service
                └─25007 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
   <Snip>
   ```  

**Note**: You do not have to perform a restore operation if your swarm is still running and you only
wish to add a new manager node. In this situation just add a new manager. A swarm restore is only for situations where the swarm is corrupted or otherwise lost and you cannot recover services from copies of config files stored in a source code repo.  

We’ll use the `swarm.bkp` file from earlier to restore the swarm. **All swarm nodes must have their Docker daemon stopped and the contents of their /var/lib/docker/swarm directories deleted**.  

The following must also be true for a recovery operation to work:
1. You can only restore to a node running the same version of Docker the backup was performed on
2. You can only restore to a node with the same IP address as the node the backup was performed on  


Perform the following tasks from the swarm manager node that you wish to recover. Remember that Docker
must be stopped and the contents of `/var/lib/docker/swarm` must be deleted.  

1. Restore the Swarm configuration from backup.
   In this example, we’ll restore from a zipped `tar` file called `swarm.bkp`. Restoring to the root directory is required with this command as it will include the full path to the original files as part of the extract operation. This may be different in your environment.
   ```
   swarm-manager-02:~# tar -zxvf swarm.bkp -C /
   ```  

2. Start Docker. The method for starting Docker can vary between environments.
   The method for starting Docker can vary between environments.
   ```
   swarm-manager-02:~# service docker start
   ```
   
3. Initialize a new Swarm cluster.  
   Remember, you are not recovering a manager and adding it back to a working cluster. This operation is to recover a failed swarm that has no surviving managers. The `--force-new-cluster` flag tells Docker to create a new cluster using the configuration stored in `/var/lib/docker/swarm/` that you recovered in step 1.
   ```
   swarm-manager-02:~# docker swarm init --force-new-cluster
   Swarm initialized: current node (jhsg...3l9h) is now a manager.
   ```  

4. Check that the network and service were recovered as part of the operation.
   ```
   swarm-manager-02:~# docker network ls
   NETWORK ID     NAME           DRIVER     SCOPE
   z21s5v82by8q   Unimatrix-01   overlay    swarm
   ```  
   
5. Add new manager and worker nodes and take fresh backups.


Congratulations. The Swarm is recovered.  
