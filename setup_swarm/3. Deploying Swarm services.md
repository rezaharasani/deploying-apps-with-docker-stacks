# Deploying Swarm services  

Services let us specify most of the familiar container options such as name, port mappings, attaching to networks, and images. But they add important cloud-native features, including `desired state` and `reconciliation`. For example, swarm services let us define the desired state for an application and let the swarm take care of deploying it and managing it.  

Let’s look at a quick example. Assume you have an app with a web front-end. You have an image for the web server and testing has shown that you need 5 instances to handle normal daily traffic. You translate this requirement into a single `service` declaring the image to use, and that the service should always have 5 running replicas. You issue that to the swarm as your desired state and the swarm takes care of ensuring there are always 5 instances of the web server running.  

You can create services in one of two ways:
1. Imperatively on the command line with `docker service create`
2. Declaratively with a stack file  

```
swarm-manager-01:~# docker service create --name web-fe -p 8080:8080 --replicas 5 \
  nigelpoulton/ddd-book:web0.1
l7cppyy983athxca8p9oij9vq
overall progress: 5 out of 5 tasks 
1/5: running   [==================================================>] 
2/5: running   [==================================================>] 
3/5: running   [==================================================>] 
4/5: running   [==================================================>] 
5/5: running   [==================================================>] 
verify: Service l7cppyy983athxca8p9oij9vq converged
```

**Terminology**: Services deploy containers, and we often call these containers replicas. For example, a service that deploys three replicas will deploy three identical containers.  

The command was sent to a manager node and the *leader manager* instantiated 5 replicas across the swarm. Managers on this swarm aren’t allowed to run application containers, meaning all 5 replicas are deployed to worker nodes. Each worker that received a work task pulled the image and started a replica listening on port *8080*. The swarm leader also ensured a copy of the desired state was stored on the cluster and replicated to every manager.  

But this isn’t the end. All *services* are constantly monitored by the swarm — the swarm runs a background `reconciliation loop` that constantly compares the `observed state` of the service with the `desired state`. If the two states match, the world is a happy place and no further action is needed. If they don’t match, swarm takes actions to bring *observed state* into line with *desired state*.  

As an example, if a worker hosting one of the 5 replicas fails, the observed state of the service will drop from 5 replicas to 4 and will no longer match the desired state of 5. As a result, the swarm will start a new replica to bring the observed state back in line with desired state. We call this `reconciliation` or `self-healing` and it’s a key tenet of cloud-native applications.  


### Viewing and inspecting services  
You can use the `docker service ls` command to see a list of all services running on a swarm.  
```
swarm-manager-01:~# docker service ls
ID             NAME       MODE         REPLICAS   IMAGE               PORTS
l7cppyy983at   web-fe     replicated   5/5        nigel...web0.1      *:8080->8080/tcp
```  

The output shows a single service and some basic config and state info. Among other things, we can see the name of the service and that 5 out of the 5 desired replicas are running. If you run this command soon after deploying the service it might not show all replicas as running. This is usually while the workers pull the image.  

You can use the `docker service ps` command to see a list of service replicas and the state of each.
```
swarm-manager-01:~# docker service ps web-fe 
ID             NAME       IMAGE            NODE              DESIRED STATE   CURRENT STATE 
hbo1341t3gaj   web-fe.1   nigel...web0.1   swarm-worker-03   Running         Running 11 minutes ago
01pb55cy036a   web-fe.2   nigel...web0.1   swarm-worker-03   Running         Running 11 minutes ago
o0629yh0cq62   web-fe.3   nigel...web0.1   swarm-worker-01   Running         Running 11 minutes ago
2vqievoc1pc2   web-fe.4   nigel...web0.1   swarm-worker-02   Running         Running 11 minutes ago
kfnsrl005ki9   web-fe.5   nigel...web0.1   swarm-worker-01   Running         Running 11 minutes ago
```  

The format of the command is `docker service ps <service-name or service-id>`. The output displays each replica on its own line, shows the node it’s running on, and shows desired state and the current observed state.  

For detailed information about a service, use the `docker service inspect` command.
```
ID:		l7cppyy983athxca8p9oij9vq
Name:		web-fe
Service Mode:	Replicated
 Replicas:	5
Placement:
UpdateConfig:
 Parallelism:	1
 On failure:	pause
 Monitoring Period: 5s
 Max failure ratio: 0
 Update order:      stop-first
RollbackConfig:
 Parallelism:	1
 On failure:	pause
 Monitoring Period: 5s
 Max failure ratio: 0
 Rollback order:    stop-first
ContainerSpec:
 Image:		nigelpoulton/ddd-book:web0.1@sha256:6b8e0d14b583...2ef8297fcaaa2a350be
 Init:		false
Resources:
Endpoint Mode:	vip
Ports:
 PublishedPort = 8080
  Protocol = tcp
  TargetPort = 8080
  PublishMode = ingress 
```

The example uses the --pretty flag to limit the output to the most interesting items printed in an easy-to-read format. Leaving off the --pretty flag will give you more info.  


### Replicated vs global services  
The default replication mode of a service is `replicated`. This deploys a desired number of replicas and distributes them as evenly as possible across the cluster. The other mode is `global`. This runs a single replica on every node in the swarm.  

To deploy a *global service* you need to pass the `--mode global` flag to the `docker service create` command. Global services do not accept the `--replicas` flag as they always run one replica per available node. However, they do respect a node’s *availability*.  

For example, if you’ve drained manager nodes so they don’t run application containers, global services will not schedule replicas to them.  


### Scaling a service
Another powerful feature of *services* is the ability to easily scale them up and down. Fortunately, we can easily scale the service up with the `docker service scale` command.  
```
swarm-manager-01:~# docker service scale web-fe=10
web-fe scaled to 10
overall progress: 10 out of 10 tasks 
1/10: running   [==================================================>] 
2/10: running   [==================================================>] 
3/10: running   [==================================================>] 
4/10: running   [==================================================>] 
5/10: running   [==================================================>] 
6/10: running   [==================================================>] 
7/10: running   [==================================================>] 
8/10: running   [==================================================>] 
9/10: running   [==================================================>] 
10/10: running   [==================================================>] 
verify: Service web-fe converged
```  

This command will scale the number of service replicas from 5 to 10. In the bachground it’s updating the service’s desired state from 5 to 10. Run another `docker service ls` command to verify the operation was successful.  
```
swarm-manager-01:~# docker service ls
ID             NAME      MODE         REPLICAS   IMAGE            PORTS
l7cppyy983at   web-fe    replicated   10/10      nigel...web0.1   *:8080->8080/tcp
```

Running a `docker service ps` command will show that the service replicas are balanced across all nodes in the swarm evenly.
```
swarm-manager-01:~# docker service ps web-fe
ID             NAME        IMAGE            NODE              DESIRED STATE   CURRENT STATE 
hbo1341t3gaj   web-fe.1    nigel...web0.1   swarm-worker-03   Running         Running 23 minutes ago
01pb55cy036a   web-fe.2    nigel...web0.1   swarm-worker-03   Running         Running 23 minutes ago
o0629yh0cq62   web-fe.3    nigel...web0.1   swarm-worker-01   Running         Running 23 minutes ago
2vqievoc1pc2   web-fe.4    nigel...web0.1   swarm-worker-02   Running         Running 23 minutes ago
kfnsrl005ki9   web-fe.5    nigel...web0.1   swarm-worker-01   Running         Running 23 minutes ago
oxpbvxlqzxut   web-fe.6    nigel...web0.1   swarm-worker-02   Running         Running 2 minutes ago
3orh9tfkwvmx   web-fe.7    nigel...web0.1   swarm-worker-03   Running         Running 2 minutes ago
kevjynowx9bt   web-fe.8    nigel...web0.1   swarm-worker-01   Running         Running 2 minutes ago
z4wdmyasp785   web-fe.9    nigel...web0.1   swarm-worker-02   Running         Running 2 minutes ago
uh3rwkyqwiuq   web-fe.10   nigel...web0.1   swarm-worker-02   Running         Running 2 minutes ago
```

Behind the scenes, Swarm runs a scheduling algorithm called **spread** that attempts to balance replicas as evenly as possible across available nodes.  

Run another `docker service scale` command to bring the number down from 10 to 5.
```
swarm-manager-01:~# docker service scale web-fe=5
web-fe scaled to 5
overall progress: 5 out of 5 tasks 
1/5: running   [==================================================>] 
2/5: running   [==================================================>] 
3/5: running   [==================================================>] 
4/5: running   [==================================================>] 
5/5: running   [==================================================>] 
verify: Service web-fe converged
```

### Removing services
Run the following `docker service rm` command to delete the web-fe service.  
```
swarm-manager-01:~# docker service rm web-fe
web-fe
```
Confirm it’s gone with the `docker service ls` command.
```
swarm-manager-01:~# docker service ls
ID             NAME      MODE         REPLICAS   IMAGE               PORTS
```  

**Note**: Be careful using this command as it deletes all service replicas without asking for confirmation.


### Rolling updates

To see this, we’re going to deploy a new service. But before we do that, we’re going to create a new overlay network for the service. This isn’t necessary, but I want you to see how it is done and how to attach the service to it.  
```
swarm-manager-01:~# docker network create -d overlay uber-net
hpadwii6inib4x7a9pbllchzb
```

Run a `docker network ls` to verify that the network created properly and is visible on the Docker host.  
```
swarm-manager-01:~# docker network ls
NETWORK ID     NAME              DRIVER    SCOPE
hpadwii6inib   uber-net          overlay   swarm
<Snip>
```

The `uber-net` network was successfully created with the swarm scope and is currently *only visible on manager nodes* in the swarm. It will be dynamically extended to worker nodes when they run workloads configured on the network.  

An *overlay network* is a layer 2 network that can span all swarm nodes. All containers on the same overlay network will be able to communicate, even if they’re deployed to different nodes. This works even if all swarm nodes are on different underlying networks.  

Figure shows four swarm nodes connected to two different underlay networks connected by a layer 3 router. The overlay network spans all 4 nodes and creates a single flat layer 2 network that abstracts all the underlying networking.  

<p align="center">
  <img src="https://github.com/arianariamehr/docker-swarm-stack-sample/assets/130653489/625052d7-f672-4a3f-a9a3-4b1644fe5ede" width="800"/>
</p>

Let’s create a new service and attach it to the uber-net network.  
```
swarm-manager-01:~# docker service create --name uber-svc \
  --network uber-net \
  -p 8080:8080 --replicas 12 \
  nigelpoulton/ddd-book:web0.1

rizjzg078gcqf2femtq1uqs9p
overall progress: 12 out of 12 tasks 
1/12: running   [==================================================>] 
2/12: running   [==================================================>] 
3/12: running   [==================================================>] 
4/12: running   [==================================================>] 
5/12: running   [==================================================>] 
6/12: running   [==================================================>] 
7/12: running   [==================================================>] 
8/12: running   [==================================================>] 
9/12: running   [==================================================>] 
10/12: running   [==================================================>] 
11/12: running   [==================================================>] 
12/12: running   [==================================================>] 
verify: Service rizjzg078gcqf2femtq1uqs9p converged
```

This mode of publishing a port on every node in the swarm — even nodes not running service replicas — is called `ingress mode` and is the *default*. The alternative mode is `host mode` which only publishes the service on swarm nodes running replicas.  

Run a `docker service ls` and a `docker service ps` command to verify the state of the new service.
```
swarm-manager-01:~# docker service ls
ID             NAME       MODE         REPLICAS   IMAGE                          PORTS
lzjydfkb8vj7   uber-svc   replicated   12/12      nigelpoulton/ddd-book:web0.1   *:8080->8080/tcp

swarm-manager-01:~# docker service ps uber-svc 
ID             NAME          IMAGE            NODE              DESIRED STATE   CURRENT STATE 
glle16ek41ex   uber-svc.1    nigel...web0.1   swarm-worker-03   Running         Running 3 minutes ago
pgbfle4sqqc5   uber-svc.2    nigel...web0.1   swarm-worker-01   Running         Running 3 minutes ago
i11as8c3nm26   uber-svc.3    nigel...web0.1   swarm-worker-03   Running         Running 3 minutes ago
fl20un18crbi   uber-svc.4    nigel...web0.1   swarm-worker-02   Running         Running 3 minutes ago
x78847292dsf   uber-svc.5    nigel...web0.1   swarm-worker-02   Running         Running 3 minutes ago
vuh9ts0gud5i   uber-svc.6    nigel...web0.1   swarm-worker-01   Running         Running 3 minutes ago
nbyz4ran8rg7   uber-svc.7    nigel...web0.1   swarm-worker-02   Running         Running 3 minutes ago
9kd01ny4uywu   uber-svc.8    nigel...web0.1   swarm-worker-03   Running         Running 3 minutes ago
dtrpaon6so7p   uber-svc.9    nigel...web0.1   swarm-worker-01   Running         Running 3 minutes ago
djm9wt7sqczf   uber-svc.10   nigel...web0.1   swarm-worker-02   Running         Running 3 minutes ago
w1vwvrdo7xuq   uber-svc.11   nigel...web0.1   swarm-worker-03   Running         Running 3 minutes ago
5ho9iuhec8r7   uber-svc.12   nigel...web0.1   swarm-worker-01   Running         Running 3 minutes ago
```

Open a web browser and point it to the IP address of any swarm node on port 8080 to see the service running.  

<p align="center">
  <img src="https://github.com/rezaharasani/deploying-apps-with-docker-stacks/assets/73277136/197134d2-a393-4fb1-b1b5-beff6fd9e95a" width="600"/>
</p>

Let’s now assume there’s another book you need to add to the site. Let’s also assume a new image has been created for it and added to the same Docker Hub repository, but this one is tagged as web0.2 instead of web0.1.  

Let’s also assume that you’ve been tasked with pushing the updated image to the swarm in a staged manner — 2 replicas at a time with a 20 second delay between each. You can use the following `docker service update` command to accomplish this.  
```
swarm-manager-01:~# docker service update \
  --image nigelpoulton/ddd-book:web0.2 \
  --update-parallelism 2 \
  --update-delay 20s \
  uber-svc

uber-svc
overall progress: 12 out of 12 tasks 
1/12: running   [==================================================>] 
2/12: running   [==================================================>] 
3/12: running   [==================================================>] 
4/12: running   [==================================================>] 
5/12: running   [==================================================>] 
6/12: running   [==================================================>] 
7/12: running   [==================================================>] 
8/12: running   [==================================================>] 
9/12: running   [==================================================>] 
10/12: running   [==================================================>] 
11/12: running   [==================================================>] 
12/12: running   [==================================================>] 
verify: Service uber-svc converged
```

Let’s review the command. `docker service update` lets us make updates to running services by updating the service’s *desired state*. This example specifies a new version of the image (web0.2 instead of web0.1). It also specifies the `--update-parallelism` and `--update-delay` flags to make sure that the new image is pushed out 2 replicas at a time with a 20 second cool-off period after each. Finally, it instructs the swarm to make the changes to the *uber-svc* service.  

If you run a `docker service ps uber-svc` while the update is in progress, some of the replicas will be on the new version and some on the old. If you give the operation enough time to complete, all replicas will eventually reach the new desired state of using the web0.2 image.  

```
swarm-manager-01:~# docker service ps uber-svc  
ID             NAME              IMAGE            NODE              DESIRED STATE   CURRENT STATE
6nq0web7aydj   uber-svc.1        nigel...web0.2   swarm-worker-03   Running         Running 7 minutes ago
glle16ek41ex    \_ uber-svc.1    nigel...web0.1   swarm-worker-03   Shutdown        Shutdown 7 minutes ago
ytb1u5ro8h7s   uber-svc.2        nigel...web0.2   swarm-worker-01   Running         Running 7 minutes ago
pgbfle4sqqc5    \_ uber-svc.2    nigel...web0.1   swarm-worker-01   Shutdown        Shutdown 7 minutes ago
jwcgf285e79n   uber-svc.3        nigel...web0.2   swarm-worker-03   Running         Running 4 minutes ago
i11as8c3nm26    \_ uber-svc.3    nigel...web0.1   swarm-worker-03   Shutdown        Shutdown 4 minutes ago
sgroth4se18m   uber-svc.4        nigel...web0.2   swarm-worker-02   Running         Running 6 minutes ago
fl20un18crbi    \_ uber-svc.4    nigel...web0.1   swarm-worker-02   Shutdown        Shutdown 6 minutes ago
75n3pnr0tmi2   uber-svc.5        nigel...web0.2   swarm-worker-02   Running         Running 5 minutes ago
x78847292dsf    \_ uber-svc.5    nigel...web0.1   swarm-worker-02   Shutdown        Shutdown 5 minutes ago
blf482bjw9pv   uber-svc.6        nigel...web0.2   swarm-worker-01   Running         Running 4 minutes ago
vuh9ts0gud5i    \_ uber-svc.6    nigel...web0.1   swarm-worker-01   Shutdown        Shutdown 4 minutes ago
cmixj53kxt9w   uber-svc.7        nigel...web0.2   swarm-worker-02   Running         Running 7 minutes ago
nbyz4ran8rg7    \_ uber-svc.7    nigel...web0.1   swarm-worker-02   Shutdown        Shutdown 7 minutes ago
j61y3y73ukqx   uber-svc.8        nigel...web0.2   swarm-worker-03   Running         Running 5 minutes ago
9kd01ny4uywu    \_ uber-svc.8    nigel...web0.1   swarm-worker-03   Shutdown        Shutdown 5 minutes ago
snn18o9nqc3l   uber-svc.9        nigel...web0.2   swarm-worker-01   Running         Running 6 minutes ago
dtrpaon6so7p    \_ uber-svc.9    nigel...web0.1   swarm-worker-01   Shutdown        Shutdown 6 minutes ago
x7jl5wphv6r3   uber-svc.10       nigel...web0.2   swarm-worker-02   Running         Running 6 minutes ago
djm9wt7sqczf    \_ uber-svc.10   nigel...web0.1   swarm-worker-02   Shutdown        Shutdown 6 minutes ago
m5zwst2qjbwy   uber-svc.11       nigel...web0.2   swarm-worker-03   Running         Running 7 minutes ago
w1vwvrdo7xuq    \_ uber-svc.11   nigel...web0.1   swarm-worker-03   Shutdown        Shutdown 7 minutes ago
kpapu6i98jh1   uber-svc.12       nigel...web0.2   swarm-worker-01   Running         Running 6 minutes ago
5ho9iuhec8r7    \_ uber-svc.12   nigel...web0.1   swarm-worker-01   Shutdown        Shutdown 6 minutes ago
```

You can observe the update in real-time by opening a web browser to any swarm node on port *8080* and hitting refresh a few times. Some of the requests will be serviced by replicas running the old version and some will be serviced by replicas running the new version. After enough time, all requests will be serviced by replicas running the updated version.

Congratulations. You’ve just completed a *zero-downtime* rolling update to a live containerized application.

If you run a `docker service inspect --pretty` command against the service, you’ll see the update parallelism and update delay settings have been merged into the service’s definition. This means future updates will automatically use these settings unless you override them as part of the docker service update command.  
```
swarm-manager-01:~# docker service inspect --pretty uber-svc

ID:		lzjydfkb8vj7y2sjzis7ldzsz
Name:		uber-svc
Service Mode:	Replicated
 Replicas:	12
Placement:
UpdateConfig:
 Parallelism:	2       <<--------
 Delay:		20s         <<--------
 On failure:	pause
 Monitoring Period: 5s
 Max failure ratio: 0
 Update order:      stop-first
RollbackConfig:
 Parallelism:	1
 On failure:	pause
 Monitoring Period: 5s
 Max failure ratio: 0
 Rollback order:    stop-first
ContainerSpec:
 Image:		Nigelpoulton/ddd-book:web0.2@sha256:3027ba56d...690ac3eb5195f80
 Init:		false
Resources:
Networks: uber-net 
Endpoint Mode:	vip
Ports:
 PublishedPort = 8080
  Protocol = tcp
  TargetPort = 8080
  PublishMode = ingress 

```

You should also note a couple of things about the service’s network config. All nodes in the swarm that are running a replica for the service will have the *uber-net* overlay network that we created earlier. We can verify this by running `docker network ls` on any node running a replica.  

You should also note the *Networks* portion of the `docker inspect` output. This shows the uber-net network as well as the swarm-wide 80:80 port mapping.  

Congratulations. You’ve just completed a *zero-downtime* rolling update to a live containerized application.  

